{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVO2DPIA6rhsJL3jAdiD0K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["'''\n","A. Data Engineering\n","'''\n","\n","'''\n","D1. Install torchtext Libraries\n","'''\n","!pip install -U torchtext==0.10.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQZxEvXjw6G_","executionInfo":{"status":"ok","timestamp":1669698880717,"user_tz":-540,"elapsed":5023,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"83707893-499d-42e1-9163-136af115bd9b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchtext==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n"]}]},{"cell_type":"code","source":["'''\n","D2. Import Libraries for Data Engineering\n","'''\n","\n","import torch\n","from torchtext.legacy import data\n","from torchtext.legacy import datasets\n","# import torch.nn.functional as F\n","\n","import numpy as np\n","\n","import random\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFOMNZqqw6KH","executionInfo":{"status":"ok","timestamp":1669698880718,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"aff84b36-aa08-42e3-e747-44a4d732df63"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["'''\n","D3. Tokenizer Install & import\n","''' \n","# Spacy Tokenizer is default. So, You are no need to install it."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Cdm6amaUzHOw","executionInfo":{"status":"ok","timestamp":1669698880718,"user_tz":-540,"elapsed":5,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"4fb4e26c-790a-4fff-ce1e-87508aefbbd5"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nD3. Tokenizer Install & import\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["'''\n","D4. Tokenizer define\n","'''\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en',\n","                  batch_first = True)\n","\n","LABEL = data.LabelField(dtype = torch.float)"],"metadata":{"id":"U-1Xj04iw6NX","executionInfo":{"status":"ok","timestamp":1669698882006,"user_tz":-540,"elapsed":1292,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["'''\n","D5. Tokenizer test\n","# PASS\n","'''\n","\n","'''\n","D6. Pad sequence\n","# PASS\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7ZnjsIshw6QX","executionInfo":{"status":"ok","timestamp":1669698882007,"user_tz":-540,"elapsed":5,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"f4881673-4846-46b2-fdb9-24183b147868"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nD6. Pad sequence\\n# PASS\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["'''\n","D7. Import dataset\n","'''\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","\n","\n","print(vars(train_data.examples[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AEmmmQdw6TP","executionInfo":{"status":"ok","timestamp":1669698925459,"user_tz":-540,"elapsed":43455,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"1f9488df-08ef-4ba1-9467-557d5bc5421c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': ['Story', 'says', 'that', 'on', 'that', 'on', 'December', '28', ',', '1895', ',', 'a', 'small', 'group', 'of', 'thirty', '-', 'three', 'people', 'was', 'gathered', 'at', 'Paris', \"'s\", 'Salon', 'Indien', 'Du', 'Grand', 'Café', 'to', 'witness', 'the', 'Cinématographe', ',', 'a', 'supposedly', 'new', 'invention', 'that', 'resulted', 'from', 'the', 'work', 'done', 'by', 'a', 'couple', 'of', 'photographers', 'named', 'August', 'and', 'Louis', 'Lumière', '.', 'The', 'small', 'audience', 'reunited', 'that', 'day', '(', 'some', 'by', 'invitation', ',', 'most', 'due', 'to', 'curiosity', ')', 'did', \"n't\", 'really', 'know', 'what', 'to', 'expect', 'from', 'the', 'show', ',', 'and', 'when', 'a', 'stationary', 'photograph', 'appeared', 'projected', 'on', 'a', 'screen', ',', 'most', 'thought', 'that', 'the', 'Cinématographe', 'was', 'just', 'another', 'fancy', 'devise', 'to', 'present', 'slide', '-', 'show', 'projections', '.', 'Until', 'the', 'photograph', 'started', 'to', 'move', '.', 'What', 'those', 'thirty', '-', 'three', 'people', 'experienced', 'in', 'awe', 'that', 'cold', 'day', 'of', 'December', 'was', 'the', 'very', 'first', 'public', 'screening', 'of', 'a', 'moving', 'picture', 'being', 'projected', 'on', 'a', 'screen', ';', 'history', 'was', 'being', 'written', 'and', 'cinema', 'as', 'we', 'know', 'it', 'was', 'born', 'that', 'day.<br', '/><br', '/>Of', 'the', '10', 'short', 'movies', 'that', 'were', 'shown', 'during', 'that', 'historic', 'day', ',', '\"', 'La', 'Sortie', 'Des', 'Usines', 'Lumière', '\"', '(', 'literally', '\"', 'Exiting', 'the', 'Lumière', 'Factory', '\"', ')', 'was', 'the', 'very', 'first', 'to', 'be', 'screened', '.', 'The', 'film', 'shows', 'the', 'many', 'workers', 'of', 'the', 'Lumière', 'factory', 'as', 'they', 'walk', 'through', 'the', 'gates', 'of', 'the', 'factory', ',', 'leaving', 'the', 'building', 'at', 'the', 'end', 'of', 'a', 'hard', 'day', 'of', 'work', '.', 'While', 'a', 'very', 'basic', '\"', 'actuality', 'film', '\"', '(', 'movie', 'depicting', 'a', 'real', 'event', ')', ',', 'the', 'movie', 'took', 'everyone', 'in', 'the', 'audience', 'by', 'surprise', ',', 'as', 'their', 'concept', 'of', 'moving', 'pictures', 'was', 'limited', 'to', 'Edison', \"'s\", '\"', 'Peep', 'Show', '\"', 'machines', '(', 'the', 'Kinetoscope', ')', ',', 'the', 'brothers', \"'\", 'invention', 'was', 'like', 'nothing', 'they', 'had', 'seen', 'before', 'and', 'so', 'the', 'audience', 'stood', 'in', 'awe', ',', 'as', 'the', 'people', 'and', 'the', 'horses', 'moved', 'across', 'the', 'screen', '.', 'The', 'idea', 'was', \"n't\", 'entirely', 'new', '(', 'Le', 'Prince', 'shot', 'the', 'first', 'movie', 'as', 'early', 'as', '1888', ')', ',', 'but', 'the', 'way', 'of', 'showing', 'the', 'movie', 'was', 'simply', 'revolutionary.<br', '/><br', '/>\"La', 'Sortie', 'Des', 'Usines', 'Lumière', '\"', 'would', 'become', 'the', 'first', 'in', 'the', 'long', 'series', 'of', '\"', 'actuality', 'films', '\"', 'that', 'the', 'Lumière', 'would', 'produce', 'over', 'the', 'years', '.', 'This', 'primitive', 'form', 'of', 'documentary', 'was', 'the', 'brothers', \"'\", 'favorite', 'kind', 'of', 'film', 'because', 'they', 'were', 'more', 'interested', 'in', 'the', 'technological', 'aspects', 'of', 'their', 'invention', 'than', 'in', 'the', 'uses', 'the', 'Cinématographe', 'could', 'have', '.', 'Despite', 'the', 'initial', 'lack', 'of', 'enthusiasm', ',', 'after', 'the', 'first', 'showing', 'the', 'Cinématographe', 'became', 'a', 'great', 'success', 'and', '\"', 'La', 'Sortie', 'Des', 'Usines', 'Lumière', '\"', 'quickly', 'became', 'an', 'iconic', 'image', 'of', 'that', 'first', 'screening', '.', 'It', 'definitely', 'was', \"n't\", 'the', 'first', 'movie', 'the', 'brothers', 'shot', 'that', 'year', ',', 'and', 'it', 'probably', 'was', \"n't\", 'the', 'best', 'of', 'the', '10', 'movies', 'shown', 'that', 'day', '(', 'personally', 'I', 'think', 'that', '\"', 'L', \"'\", 'Arroseur', 'Arrosé', '\"', 'was', 'the', 'best', 'of', 'the', '10', ')', ';', 'however', ',', 'it', 'is', 'really', 'meaningful', 'that', 'the', 'very', 'first', 'movie', 'was', 'the', 'opening', 'of', 'a', 'pair', 'of', 'gates', ',', 'as', 'literally', ',', 'this', 'movie', 'opened', 'the', 'gates', 'to', 'cinema', 'as', 'we', 'know', 'it', '.', '8/10'], 'label': 'pos'}\n"]}]},{"cell_type":"code","source":["'''\n","D8. Split\n","'''\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n","\n","print(f'Number of training examples   : {len(train_data)}')\n","print(f'Number of validation examples : {len(valid_data)}')\n","print(f'Number of testing examples    : {len(test_data)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-SxoJ87w6WH","executionInfo":{"status":"ok","timestamp":1669698925460,"user_tz":-540,"elapsed":12,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"c0bd631e-a08c-4c18-db38-fd2e03c9bc98"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples   : 17500\n","Number of validation examples : 7500\n","Number of testing examples    : 25000\n"]}]},{"cell_type":"code","source":["'''\n","D9. Build vocaburary\n","'''\n","MAX_VOCAB_SIZE = 20000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","\n","LABEL.build_vocab(train_data)\n","\n","print(f\"Unique tokens in TEXT vocabulary : {len(TEXT.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n","\n","print(TEXT.vocab.freqs.most_common(20))\n","\n","print(TEXT.vocab.itos[:10])\n","\n","print(LABEL.vocab.stoi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBmsObchw6Y3","executionInfo":{"status":"ok","timestamp":1669698925939,"user_tz":-540,"elapsed":490,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"3336466b-a47c-4ebe-b65d-f299430756d0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in TEXT vocabulary : 20002\n","Unique tokens in LABEL vocabulary: 2\n","[('the', 203004), (',', 192481), ('.', 165623), ('and', 109580), ('a', 109493), ('of', 101261), ('to', 93966), ('is', 76388), ('in', 61350), ('I', 54350), ('it', 53729), ('that', 49441), ('\"', 44527), (\"'s\", 43334), ('this', 42403), ('-', 37597), ('/><br', 35785), ('was', 35159), ('as', 30402), ('with', 29951)]\n","['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n","defaultdict(None, {'neg': 0, 'pos': 1})\n"]}]},{"cell_type":"code","source":["'''\n","D10. Dataload with Iterator\n","# PASS\n","'''\n","\n","'''\n","D11. Data type define\n","# PASS\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bvGd-LUKw6bX","executionInfo":{"status":"ok","timestamp":1669698925939,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"a8d68126-68b1-4eee-d4e4-7c546ddb4039"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nD11. Data type define\\n# PASS\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["'''\n","D12. Dataload with BucketIterator\n","'''\n","BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    device = device)\n","\n","print('Number of minibatch for training dataset   : {}'.format(len(train_iterator)))\n","print('Number of minibatch for validation dataset : {}'.format(len(valid_iterator)))\n","print('Number of minibatch for testing dataset    : {}'.format(len(test_iterator)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgcLwc09w6eH","executionInfo":{"status":"ok","timestamp":1669698925940,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"a79e0db6-38a3-4c68-df50-7527adc5bf4b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of minibatch for training dataset   : 274\n","Number of minibatch for validation dataset : 118\n","Number of minibatch for testing dataset    : 391\n"]}]},{"cell_type":"code","source":["'''\n","B. Model Engineering\n","'''\n","\n","'''\n","M1. Import Libraries for Model Engineering\n","'''\n","import torch.nn as nn"],"metadata":{"id":"d2d4-hWJw6hH","executionInfo":{"status":"ok","timestamp":1669698925941,"user_tz":-540,"elapsed":5,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["'''\n","M2. Set Hyperparameters\n","'''\n","embedding_dim = 256\n","hidden_units = 128\n","EPOCHS = 50\n","learning_rate = 5e-4"],"metadata":{"id":"rgKHo4bGw6kJ","executionInfo":{"status":"ok","timestamp":1669698925941,"user_tz":-540,"elapsed":5,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["'''\n","M4. Build NN model\n","'''\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, hidden_dim, output_dim, embedding_dim, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n","        self.linear = nn.Linear(hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        embedded = self.dropout(self.embedding(text))\n","        output, _ = self.rnn(embedded)\n","        output = self.linear(output[:, -1, :])\n","        return output\n","  \n","    def _init_state(self, batch_size=1):\n","        weight = next(self.parameters()).data\n","        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","\n","model = LSTM(len(TEXT.vocab), 128, len(LABEL.vocab)-1, 300, 0.2)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tmwy4nyXw6m2","executionInfo":{"status":"ok","timestamp":1669698926225,"user_tz":-540,"elapsed":289,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"3f1612eb-f558-469b-b488-d07c024a807d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 6,220,889 trainable parameters\n"]}]},{"cell_type":"code","source":["'''\n","M5. Optimizer\n","'''\n","import torch.optim as optim\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"L2aQLzTZw6pv","executionInfo":{"status":"ok","timestamp":1669698926226,"user_tz":-540,"elapsed":3,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["'''\n","M6. Define Loss Function\n","'''\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"id":"Ut8MxFD3w6sn","executionInfo":{"status":"ok","timestamp":1669698926226,"user_tz":-540,"elapsed":3,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["'''\n","M7. Define Accuracy Function\n","'''\n","def binary_accuracy(preds, target):\n","    '''\n","    from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n","    '''\n","    # round predictions to the closest integer (0 or 1)\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","\n","    #convert into float for division\n","    correct = (rounded_preds == target).float()\n","\n","    # rounded_preds = [ 1   0   0   1   1   1   0   1   1   1]\n","    # targets       = [ 1   0   1   1   1   1   0   1   1   0]\n","    # correct       = [1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0]\n","    acc = correct.sum() / len(correct)\n","    return acc"],"metadata":{"id":"hMstyJO8w6vo","executionInfo":{"status":"ok","timestamp":1669698926226,"user_tz":-540,"elapsed":3,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["'''\n","M8. Define Training Function\n","'''\n","def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        # We initialize the gradient to 0 for every batch.\n","        optimizer.zero_grad()\n","\n","        # batch of sentences인 batch.text를 model에 입력\n","        predictions = model(batch.text).squeeze(1)\n","        \n","        # Calculate the loss value by comparing the prediction result with batch.label \n","        loss = criterion(predictions, batch.label)\n","\n","        # Accuracy calculation\n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        # Backpropagation using backward()\n","        loss.backward()\n","\n","        # Update the parameters using the optimization algorithm\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"57bMKglsw6yx","executionInfo":{"status":"ok","timestamp":1669698926227,"user_tz":-540,"elapsed":4,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["'''\n","M9. Define Validation / Test Function\n","'''\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    # \"evaluation mode\" : turn off \"dropout\" or \"batch nomalizaation\"\n","    model.eval()\n","\n","    # Use less memory and speed up computation by preventing gradients from being computed in pytorch\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","            \n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"fqZ7YIIAw61o","executionInfo":{"status":"ok","timestamp":1669698926227,"user_tz":-540,"elapsed":3,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","\n","best_valid_loss = float('inf')\n","\n","'''\n","M10. Episode / each step Process\n","'''\n","for epoch in range(EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut4-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbEzLjNew64X","executionInfo":{"status":"ok","timestamp":1669699966778,"user_tz":-540,"elapsed":1040554,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"0fbe8999-b72f-4519-f8a2-3042b32ed6e0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 0m 22s\n","\tTrain Loss: 0.695 | Train Acc: 49.41%\n","\t Val. Loss: 0.693 |  Val. Acc: 50.97%\n","Epoch: 02 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.693 | Train Acc: 50.07%\n","\t Val. Loss: 0.694 |  Val. Acc: 49.70%\n","Epoch: 03 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.693 | Train Acc: 49.83%\n","\t Val. Loss: 0.692 |  Val. Acc: 51.43%\n","Epoch: 04 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.692 | Train Acc: 50.00%\n","\t Val. Loss: 0.693 |  Val. Acc: 51.93%\n","Epoch: 05 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.690 | Train Acc: 50.32%\n","\t Val. Loss: 0.700 |  Val. Acc: 53.45%\n","Epoch: 06 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.689 | Train Acc: 50.28%\n","\t Val. Loss: 0.698 |  Val. Acc: 53.47%\n","Epoch: 07 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.688 | Train Acc: 50.88%\n","\t Val. Loss: 0.709 |  Val. Acc: 53.27%\n","Epoch: 08 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.687 | Train Acc: 50.93%\n","\t Val. Loss: 0.716 |  Val. Acc: 53.71%\n","Epoch: 09 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.687 | Train Acc: 50.36%\n","\t Val. Loss: 0.718 |  Val. Acc: 53.35%\n","Epoch: 10 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.686 | Train Acc: 51.03%\n","\t Val. Loss: 0.730 |  Val. Acc: 54.82%\n","Epoch: 11 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.686 | Train Acc: 50.75%\n","\t Val. Loss: 0.734 |  Val. Acc: 54.45%\n","Epoch: 12 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.686 | Train Acc: 50.78%\n","\t Val. Loss: 0.740 |  Val. Acc: 54.46%\n","Epoch: 13 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.686 | Train Acc: 51.10%\n","\t Val. Loss: 0.738 |  Val. Acc: 54.50%\n","Epoch: 14 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.685 | Train Acc: 50.92%\n","\t Val. Loss: 0.744 |  Val. Acc: 54.90%\n","Epoch: 15 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.683 | Train Acc: 52.76%\n","\t Val. Loss: 0.763 |  Val. Acc: 63.56%\n","Epoch: 16 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.634 | Train Acc: 67.39%\n","\t Val. Loss: 0.605 |  Val. Acc: 72.38%\n","Epoch: 17 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.569 | Train Acc: 75.15%\n","\t Val. Loss: 0.572 |  Val. Acc: 75.52%\n","Epoch: 18 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.569 | Train Acc: 72.04%\n","\t Val. Loss: 0.555 |  Val. Acc: 73.15%\n","Epoch: 19 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.534 | Train Acc: 75.53%\n","\t Val. Loss: 0.648 |  Val. Acc: 65.16%\n","Epoch: 20 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.493 | Train Acc: 79.29%\n","\t Val. Loss: 0.475 |  Val. Acc: 80.67%\n","Epoch: 21 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.414 | Train Acc: 84.20%\n","\t Val. Loss: 0.467 |  Val. Acc: 81.33%\n","Epoch: 22 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.383 | Train Acc: 85.95%\n","\t Val. Loss: 0.440 |  Val. Acc: 82.58%\n","Epoch: 23 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.359 | Train Acc: 87.07%\n","\t Val. Loss: 0.472 |  Val. Acc: 80.34%\n","Epoch: 24 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.333 | Train Acc: 87.96%\n","\t Val. Loss: 0.492 |  Val. Acc: 82.00%\n","Epoch: 25 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.320 | Train Acc: 88.66%\n","\t Val. Loss: 0.456 |  Val. Acc: 83.48%\n","Epoch: 26 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.292 | Train Acc: 89.51%\n","\t Val. Loss: 0.427 |  Val. Acc: 83.81%\n","Epoch: 27 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.268 | Train Acc: 90.74%\n","\t Val. Loss: 0.427 |  Val. Acc: 84.12%\n","Epoch: 28 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.268 | Train Acc: 90.64%\n","\t Val. Loss: 0.405 |  Val. Acc: 85.34%\n","Epoch: 29 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.235 | Train Acc: 92.19%\n","\t Val. Loss: 0.418 |  Val. Acc: 85.25%\n","Epoch: 30 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.221 | Train Acc: 92.82%\n","\t Val. Loss: 0.415 |  Val. Acc: 85.17%\n","Epoch: 31 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.216 | Train Acc: 92.77%\n","\t Val. Loss: 0.409 |  Val. Acc: 85.68%\n","Epoch: 32 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.194 | Train Acc: 93.90%\n","\t Val. Loss: 0.423 |  Val. Acc: 86.06%\n","Epoch: 33 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.192 | Train Acc: 93.84%\n","\t Val. Loss: 0.413 |  Val. Acc: 86.01%\n","Epoch: 34 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.167 | Train Acc: 94.83%\n","\t Val. Loss: 0.417 |  Val. Acc: 85.95%\n","Epoch: 35 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.158 | Train Acc: 95.12%\n","\t Val. Loss: 0.421 |  Val. Acc: 86.33%\n","Epoch: 36 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.210 | Train Acc: 92.92%\n","\t Val. Loss: 0.509 |  Val. Acc: 80.47%\n","Epoch: 37 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.205 | Train Acc: 92.90%\n","\t Val. Loss: 0.461 |  Val. Acc: 85.99%\n","Epoch: 38 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.148 | Train Acc: 95.36%\n","\t Val. Loss: 0.422 |  Val. Acc: 86.42%\n","Epoch: 39 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.131 | Train Acc: 96.08%\n","\t Val. Loss: 0.418 |  Val. Acc: 86.86%\n","Epoch: 40 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.119 | Train Acc: 96.52%\n","\t Val. Loss: 0.432 |  Val. Acc: 86.49%\n","Epoch: 41 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.114 | Train Acc: 96.66%\n","\t Val. Loss: 0.442 |  Val. Acc: 86.37%\n","Epoch: 42 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.106 | Train Acc: 97.04%\n","\t Val. Loss: 0.447 |  Val. Acc: 86.44%\n","Epoch: 43 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.103 | Train Acc: 97.10%\n","\t Val. Loss: 0.445 |  Val. Acc: 86.78%\n","Epoch: 44 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.094 | Train Acc: 97.30%\n","\t Val. Loss: 0.469 |  Val. Acc: 87.13%\n","Epoch: 45 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.093 | Train Acc: 97.35%\n","\t Val. Loss: 0.470 |  Val. Acc: 86.93%\n","Epoch: 46 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.085 | Train Acc: 97.70%\n","\t Val. Loss: 0.448 |  Val. Acc: 87.14%\n","Epoch: 47 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.078 | Train Acc: 97.81%\n","\t Val. Loss: 0.465 |  Val. Acc: 87.18%\n","Epoch: 48 | Epoch Time: 0m 21s\n","\tTrain Loss: 0.092 | Train Acc: 97.37%\n","\t Val. Loss: 0.451 |  Val. Acc: 86.71%\n","Epoch: 49 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.075 | Train Acc: 98.02%\n","\t Val. Loss: 0.447 |  Val. Acc: 87.18%\n","Epoch: 50 | Epoch Time: 0m 20s\n","\tTrain Loss: 0.070 | Train Acc: 98.07%\n","\t Val. Loss: 0.476 |  Val. Acc: 87.37%\n"]}]},{"cell_type":"code","source":["'''\n","M11. Assess model performance (Test step)\n","'''\n","model.load_state_dict(torch.load('tut4-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n","\n","import torch\n","model.load_state_dict(torch.load('tut4-model.pt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkbKCmV3ziRX","executionInfo":{"status":"ok","timestamp":1669699970361,"user_tz":-540,"elapsed":3585,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"22879f64-4bae-4922-b75c-02cc1194c45d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.442 | Test Acc: 84.21%\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["'''\n","M12. [Opt] Training result test for Code Engineering\n","'''\n","import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def predict_sentiment(model, sentence, min_len = 5):\n","    model.eval()\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n","    if len(tokenized) < min_len:\n","        tokenized += ['<pad>'] * (min_len - len(tokenized))\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(0)\n","    prediction = torch.sigmoid(model(tensor))\n","    return prediction.item()\n","\n","examples = [\n","  \"This film is terrible\",\n","  \"This film is great\",\n","  \"This movie is fantastic\"\n","]\n","\n","for idx in range(len(examples)) :\n","\n","    sentence = examples[idx]\n","    pred = predict_sentiment(model,sentence)\n","    print(\"\\n\",sentence)\n","    if pred >= 0.5 :\n","        print(f\">>>This is a positive review. ({pred : .2f})\")\n","    else:\n","        print(f\">>>This is a negative review.({pred : .2f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4GwjiUhw7Kn","executionInfo":{"status":"ok","timestamp":1669699970982,"user_tz":-540,"elapsed":625,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"adaccefb-9b42-4c31-9b94-23a042767571"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," This film is terrible\n",">>>This is a negative review.( 0.23)\n","\n"," This film is great\n",">>>This is a positive review. ( 0.75)\n","\n"," This movie is fantastic\n",">>>This is a positive review. ( 0.69)\n"]}]}]}